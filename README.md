# Auth 1B

## 1. Basic Knowledge

### a. Authentication vs Authorization:

+ AuthN: who you are
    + sth you know: password
    + sth you have: physical devices
    + sth you are: biometrics
    + some authentication methods: 
        + password-based
        + multi-factor authN (MFA)
        + single-sign on (SSO)
        + magic link/passwordless
+ AuthZ: what you have access to
    + usually done after successfull authentication
    + info is transmitted through an Access Token (Authorization credential, in the form of an opaque string or JWT, used to access an API)
    + Role-based access control (RBAC)

### b. Session-based vs Token-based Authentication

+ make a server trust any request sent by an authenticated user over the internet --> a user can interact with their account without continually specifying their credentials.

+ session-based authN:
    + small file about the user, generated and stored on the server to keep track of the user requests
    + user interacts with server via session ID 
    + pros: since sessions are stored on the server, its admins are in power over them.
    + cons: since a session is stored on the server, the server is in charge of looking up the session ID, this can cause scalability problems 

+ token-based authN:
    + cannot be tampered with, generated by the server using a secret key, sent to and stored by the user in their local storage
    + user sends this token to the server with every new request, so that the server can verify its signature and authorize the requests.
    + pros: improve thei performances because the server do not need to continuously look through all the session details to authorize the user's requests
    + cons: the server cannot perform certain security operations as in the session method 

### c. Password Storage Basics

+ when passwords are stored properly, they must be protected from an attacker even if the application or database is compromised, include offline password cracking 

+ hashing vs encryption
    + both can keep sensitive data safe, but in almost all circumstances, passwords should be hashed, NOT encrypted.
    + hashing is a `one-way function`, a one-way blender, impossible to "decrypt" a hash and obtain the original plaintext value --> even if an attacker obtains the hashed password, they cannot use it to log in as the victim
    + encryption is a `two-way function`, attackers can retrieve the original plaintext from the encrypted data
    + the only time encryption should be used in passwords is in edge cases where it is necessary to obtain the original plaintext password, when the app needs to authen with another system that does not support a modern way to programmatically grant access, such as OpenID Connect (OIDC)

+ strong passwords stored with modern hashing algorithms and using hashing best practices should be effectively impossible for an attacker to crack.

+ how attackers can crack your password
    + select a password you think the victim has chosen (e.g. password1!), calculating the hash then comparing the hash you calculated to the hash of the victim
    + attackers will repeat this process with a list of large number of potential candidate passwords, with high speed hardware (GPUs) and cloud services with many server for rent
        + rainbow table

+ methods for enhancing password storage
    + salting: a unique, randomly generated string for each password --> protect against rainbow tables, no 2 users have the same password without cracking the hashes. Modern hashing algorithms such as Argon2id, bcrypt and PBKDF2 automatically salt the passwords
    + peppering: additional layer of protection, it is shared between stored passwords, should not be public and should not be stored along with the generated hash. The pepper should be stored separately from the password database. It prevents an attacker from being able to crack any of hashes if they only have access to the database.
        + pre-hashing peppers
        + post-hashing peppers

+ password hashing algorithms
    + argon2id
    + scrypt
    + bcrypt (should only be used for password storage in legacy systems where Argon2 and scrypt are not available)
    + PBKDF2

## 2. Project

### a. Simple jwt authentication

> referrer: https://www.bezkoder.com/node-js-jwt-authentication-postgresql/

+ techstack: nodejs + express + postgresql + sequelize (ORM) + docker
    + token-based authentication, there are 3 important parts of a JWT: `[header].[payload].[signature]`. Client typically attaches JWT in `Authorization` header with `Bearer` prefix or in `x-access-token` header on each request after successful authentication.
    + referrer:
        + https://sequelize.org/
+ overview of this app:
    + user can signup new account, or login with username & password
    + user info will be stored in PostgreSQL database
    + by user's role (admin, moderator, user), we authorize the user to access resources

+ apis we need to provide:

    | Methods   | Urls              | Actions               |
    |-----------|-------------------|-----------------------|
    | POST      | /api/auth/signup  | signup new account    |
    | POST      | /api/auth/signin  | login an account      |
    | GET       | /api/test/all     | retrieve public content   |
    | GET       | /api/test/user    | access User's content |
    | GET       | /api/test/mod     | access Moderator's content    |
    | GET       | /api/test/admin   | access Admin's content    |


+ flow for signup & login 

    <img src="./images/authN-flow.png" height="400">

+ and we need to implement `Refresh Token`:

    <img src="./images/refresh-token-flow.png" height="400">

+ nodejs express architecture with authN & authZ:

    <img src="./images/nodejs-express-architecture.png" height="400">

    + Via Express routes, HTTP request that matches a route will be checked by CORS middleware before coming to Security layer (JWT authN middleware and authZ middleware)
    + if these middlewares throw any error, a message will be sent as HTTP response
    + Controllers interact with PostgreSQL database via Sequelize and send HTTP response to client.

+ dockerize application
    + after complete `docker-compose.yml`, workflow:
        + `docker compose up --build`, rebuild image if Dockerfile is changed -> restart app + db
        + `docker compose up`, no rebuild, just restart container -> volume mount hot-reload automatically
        + `docker compose down`, stop + delete container (DB is still alive via volume)
        + `docker compose down -v`, reset everything, include DB
    + docker + nodemon for dev environment
        + changing code won't restart the server, refer: https://stackoverflow.com/questions/27226653/nodemon-is-not-working-in-docker-environment
    + referrer: 
        + https://www.bezkoder.com/docker-compose-nodejs-postgres/
        + https://dev.to/nodepractices/docker-best-practices-with-node-js-4ln4
        + https://www.digitalocean.com/community/tutorials/how-to-build-a-node-js-application-with-docker

### b. Securing passwords in Node.js: the Argon2 way

> https://hackernoon.com/argon2-in-practice-how-to-implement-secure-password-hashing-in-your-application

+ Argon2 was specifically designed to counter the most elegant attack vectors that we have today --> password hashing champion.

+ pros:
    + memory-hardness: argon2 uses huge amounts of memory while hashing. --> scalable use of GPUs or ASICs cannot be relied upon by attackers in cracking passwords --> very expensive in parallel computing environments
    + tunable parameters: adjust on memory capacity usage, parallelism and execution time
    + defense-in-depth: designed to resist not only brute-force attacks, but also side-channel attacks, time-memory trade-offs, and many other complicated ways hackers break passwords.

+ we will use `argon2id`, the hybrid solution from `argon2i` and `argon2d`, and the one most often recommended. In Node.js world, `argon2` is probably the most famous package binding to the C implementation

    ```bash
    $ npm install argon2
    ```

+ actual implementation: hashing passwords with argon2
    + step 1: generate a cryptographically secure salt. In node.js,  we use `crypto.randomBytes()`. A salt length should preferably be 16 bytes or more (128bits) in size.
    + step 2: set up Argon2 parameters (where the most common mistakes occur for many devs). Benchmarking it on the server and calibrating your params to obtain a hashing time of 250-500ms.
        + Memory cost: how much memory the algorithm will use, the more the better is for security. (KiB)
        + Time cost: the number of iterations or passes over the memory. High is slow but provides more security.
        + Parallelism: how many parallel threds should it use? usually, that should match the number of available CPU cores
        + Hash length: the output size of the hash expressed in bytes
    + step 3: call the Argon2 Hash function

    ```javascript
    <!-- Nodejs example -->
    const argon2 = require('argon2');
    const crypto = require('crypto');
    // we can use additional PEPPER
    async function hashPassword(password) {
        // Configure the algorithm
        const options = {
            type: argon2.argon2id,    // Variant of Argon2
            memoryCost: 65536,        // 64 MiB
            timeCost: 2,              // 2 passes
            parallelism: 4,           // 4 threads
            hashLength: 32,           // 32 bytes output
            saltLength: 16,           // 16 bytes salt
            // You can also provide your own salt:
            // salt: crypto.randomBytes(16) 
        };
        
        try {
            // Hash the password (salt is generated automatically by default)
            const hash = await argon2.hash(password, options);
            return hash;
        } catch (err) {
            console.error('Error hashing password:', err);
            throw err;
        }
    }

    // Example usage
    hashPassword('super_secret_password')
        .then(hash => console.log('Hashed password:', hash))
        .catch(err => console.error(err));

    // This will produce something like:
    // $argon2id$v=19$m=65536,t=3,p=4$G8NYSxrA+UMGHJbZVIXXXQ$UrHyBcYfCEms+92QVzGmfYqrWtH54WJY9FuROBQi/X8
    ```
+ Understanding the Output Format
    ```javascript
    $argon2id$v=19$m=65536,t=3,p=4$G8NYSxrA+UMGHJbZVIXXXQ$UrHyBcYfCEms+92QVzGmfYqrWtH54WJY9FuROBQi/X8
    ```
    + `$argon2id`: the variant of the algorithm
    + `v=19`: version of the argon2 
    + `m=65536,t=3,p=4`: parameters (memory=65536 KiB, time=3 iterations, parallelism=4 threads)
    + `G8NYSxrA+UMGHJbZVIXXXQ`: base64-encoded salt
    + `UrHyBcYfCEms+92QVzGmfYqrWtH54WJY9FuROBQi/X8`: base64-encoded hash

+ Verifying Passwords Securely

    ```javascript
    const argon2 = require('argon2');

    async function verifyPassword(storedHash, providedPassword) {
        try {
            // The verify function returns true if the password matches
            // It returns false if the password doesn't match
            const isValid = await argon2.verify(storedHash, providedPassword);
            return isValid;
        } catch (err) {
            // Handle errors like invalid hash format
            console.error('Error during password verification:', err);
            return false;
        }
    }

    // Example usage
    const storedHash = '$argon2id$v=19$m=65536,t=3,p=4$G8NYSxrA+UMGHJbZVIXXXQ$UrHyBcYfCEms+92QVzGmfYqrWtH54WJY9FuROBQi/X8';

    verifyPassword(storedHash, 'super_secret_password')
        .then(isValid => {
            if (isValid) {
                console.log('Password is correct!');
            } else {
                console.log('Password is incorrect!');
            }
        })
        .catch(err => console.error(err));
    ```
### c. Access tokens (JWTs) and Refresh tokens. Refresh token rotation and reuse detection

+ JWTs are portable units of identity. They contain identity information as JSON and can be passed around to services and apps.
    + The service/app receiving a JWT doesn't need to ask the identity provider that generated the JWT if it is valid
    + Once a JWT is verified, the service/app can use the data inside it to take action on behalf of the user

+ JWTs expire at specific intervals: it is quite different with traditional session. 
    + for security purposes, access tokens (JWTs) may be valid for a short amount of time (usually 10-30 minutes to minimize risk)
    + refresh tokens appear - opaque tokens that are used to generate new JWTs. Once JWTs expire, client apps can use a refresh token to "refresh" the access token without having to ask the user to log in again.

+ JWTs are cryptographically signed: they require a cryptographic algorithm to verify

    <img src="images/jwt-structure.png" height=400>

    + RSA public-private key signing: slow signing using private key and fast verifying using public key. On a quad-core MacBook Pro, about 200 JWT/s. This number drops dramatically on virtualized hardware like Amazon EC2s
    + HMAC signing: much faster but lacks the same flexibility and security characteristics. If the identity provider uses HMAC to sign a JWT, then all services that want to verify the JWT must have the HMAC secret --> this means that all the services can now crete and sign JWTs as well --> less portable and less secure

+ JWTs aren't easily revocable: JWT could be valid even though the user's account has been suspended or deleted
    + solution: https://fusionauth.io/articles/tokens/revoking-jwts

+ JWTs have exploits:
    <later>

+ Alone access token is not enough for security, we need to implement both access token and refresh token. But we need to implement it properly.
    + access token = short time, refresh token = long time
    + access token: sent as JSON, client stores in memory, DO NOT store in local storage or cookie
    + refresh token: sent as httpOnly cookie, not accessible via JavaScript, must have expiry at some point
    + access token: sent with every api request until expires, new token issued at Refresh request

    + Normal login flow with JWT:

    <img src="./images/normal-login-flow-with-jwt.png" height=400>

    + Login flow with access token & refresh token

    <img src="./images/login-flow-with-access-token-n-refresh-token-1.png" height=400>

    + what if tokens expire
    
    <img src="./images/login-flow-with-access-token-n-refresh-token-2.png" height=400>

    + refresh token rotation and reuse detection: 
        + ref: https://www.youtube.com/watch?v=s-4k5TcGKHg
        
        + what if refresh token is comprised? --> malicious access would be granted until the refresh token expires
        + refresh token rotation: when a new access token is issued, a new refresh token is also issued
        + reuse detection: a refresh token can only be used once. If reuse is detected, all refresh tokens are invalidated for the user which will force a new login for authentication.
+ Keeping refresh tokens secure: refresh tokens are also bearer tokens --> we need to have a strategy in place that limits or curtails their usage if they ever get leaked or become compromised
    + refresh token rotation: a technique for getting new access tokens using refresh tokens that goes beyond [silent-authentication](https://auth0.com/docs/authenticate/login/configure-silent-authentication). It guarantees that every time an app exchanges a refresh token to get a new access token, a new refresh token is also returned
    + refresh token automatic reuse detection: refresh tokens are bearer tokens --> impossible for the authorization server to know who is legitimate or malicious when receiving a new access token request --> treat all users as potentially malicious --> detect reuse refresh token --> denial all! --> requires re-authentication to get new access and refresh tokens
    + when we have refresh token rotation in place, we can store tokens in local storage or browser memory even if XSS attack happens!!

+ we now have 2 apis more: 

    | Methods   | Urls              | Actions               |
    |-----------|-------------------|-----------------------|
    | POST      | /api/auth/signup  | signup new account    |
    | POST      | /api/auth/signin  | login an account      |
    | POST      | /api/auth/refresh | refresh access token  |
    | GET       | /api/auth/logout  | logout                |
    | GET       | /api/test/all     | retrieve public content   |
    | GET       | /api/test/user    | access User's content |
    | GET       | /api/test/mod     | access Moderator's content    |
    | GET       | /api/test/admin   | access Admin's content    |

+ And lastly, we can implement periodic cleanup job for automatically DB cleanup expired refresh token 
    + using Node.js cron job (inside the app)
    + using PostgreSQL `pg_cron` extension (high-recommended strategy)

### d. Implement rate limiting, CAPTCHA and lockout policies

+ rate limiting:
    + https://dev.to/hamzakhan/api-rate-limiting-in-nodejs-strategies-and-best-practices-3gef
    + control the number of requests a client can make to the API within a specified timeframe
    + why it matters:
        + enhancing security: preventing brute-force attacks
        + improving performance: ensuring fair resource allocation   
        + maintaining stability: avoiding server overload   
    + leveraging `express-rate-limit` for basic limiting
        + https://www.npmjs.com/package/express-rate-limit
        + limitations of basic rate limiting:
            + shared across all routes
            + inflexible for diverse API endpoints
    + distributed rate limiting with redis
        + https://www.sudshekhar.com/blog/api-rate-limiting-redis-nodejs
        + when running APIs on multiple servers, in-memory rate limiting falls short. Redis, a fast, in-memory data store, provides a robust solution for distributed rate limiting.
        + pros. Supports distributed systems, Customizable for different endpoints
    + token bucket algorithm for advanced rate limiting
        + https://dev.to/hexshift/rate-limiting-in-nodejs-using-redis-and-token-bucket-algorithm-30ah
    + find-grained rate limiting with api gateways
    + monitoring and alerts: using tools like `datadog` or `prometheus` to monitor request rates, rejected request (http 429) and api performance metrics
    + benchmark.
    + best practices for API rate limiting:
        + Use redis or API gateway for distributed setups
        + apply different rate limits for free vs premium users
        + always provide clear error message 
        + monitor and fine-tune based on traffic patterns
        + production = redis + token bucket algorithm + prometheus; nginx. Only use express-rate-limit for dev/local
    